10/12/2024 13:48:25 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False, 16-bits training: False
10/12/2024 13:48:26 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/workspace/text-code/dataset/train.jsonl', output_dir='/workspace/text-code/saved_models', eval_data_file='/workspace/text-code/dataset/valid.jsonl', test_data_file='/workspace/text-code/dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/codebert-base', mlm=False, mlm_probability=0.15, config_name='microsoft/codebert-base', tokenizer_name='roberta-base', cache_dir='', block_size=256, do_train=True, do_eval=False, do_test=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=64, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=2, fp16=False, fp16_opt_level='O2', local_rank=-1, server_ip='', server_port='', n_gpu=2, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=32, start_epoch=0, start_step=0)
10/12/2024 13:50:38 - INFO - __main__ -   *** Example ***
10/12/2024 13:50:38 - INFO - __main__ -   idx: 0
10/12/2024 13:50:38 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
10/12/2024 13:50:38 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/12/2024 13:50:38 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
10/12/2024 13:50:38 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/12/2024 13:50:38 - INFO - __main__ -   *** Example ***
10/12/2024 13:50:38 - INFO - __main__ -   idx: 1
10/12/2024 13:50:38 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
10/12/2024 13:50:38 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/12/2024 13:50:38 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/12/2024 13:50:38 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/12/2024 13:50:38 - INFO - __main__ -   *** Example ***
10/12/2024 13:50:38 - INFO - __main__ -   idx: 2
10/12/2024 13:50:38 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
10/12/2024 13:50:38 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/12/2024 13:50:38 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
10/12/2024 13:50:38 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/opt/conda/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
10/12/2024 13:50:42 - INFO - __main__ -   ***** Running training *****
10/12/2024 13:50:42 - INFO - __main__ -     Num examples = 251820
10/12/2024 13:50:42 - INFO - __main__ -     Num Epochs = 2
10/12/2024 13:50:42 - INFO - __main__ -     Instantaneous batch size per GPU = 32
10/12/2024 13:50:42 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
10/12/2024 13:50:42 - INFO - __main__ -     Gradient Accumulation steps = 1
10/12/2024 13:50:42 - INFO - __main__ -     Total optimization steps = 7870
trainable params: 1,179,648 || all params: 125,825,280 || trainable%: 0.9375
/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
10/12/2024 13:52:32 - INFO - __main__ -   epoch 0 step 100 loss 16.00302
10/12/2024 13:54:21 - INFO - __main__ -   epoch 0 step 200 loss 13.24423
10/12/2024 13:56:11 - INFO - __main__ -   epoch 0 step 300 loss 10.56521
10/12/2024 13:57:58 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 13:57:58 - INFO - __main__ -     Num examples = 9604
10/12/2024 13:57:58 - INFO - __main__ -     Batch size = 64
10/12/2024 13:59:28 - INFO - __main__ -     eval_loss = 1.7971
10/12/2024 13:59:28 - INFO - __main__ -     eval_mrr = 0.0884
10/12/2024 13:59:28 - INFO - __main__ -     ********************
10/12/2024 13:59:28 - INFO - __main__ -     Best mrr:0.0884
10/12/2024 13:59:28 - INFO - __main__ -     ********************
10/12/2024 13:59:33 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 13:59:41 - INFO - __main__ -   epoch 0 step 400 loss 1.32488
10/12/2024 14:01:29 - INFO - __main__ -   epoch 0 step 500 loss 0.8802
10/12/2024 14:03:18 - INFO - __main__ -   epoch 0 step 600 loss 0.6513
10/12/2024 14:05:08 - INFO - __main__ -   epoch 0 step 700 loss 0.54925
10/12/2024 14:06:40 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:06:40 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:06:40 - INFO - __main__ -     Batch size = 64
10/12/2024 14:08:11 - INFO - __main__ -     eval_loss = 1.3267
10/12/2024 14:08:11 - INFO - __main__ -     eval_mrr = 0.2347
10/12/2024 14:08:11 - INFO - __main__ -     ********************
10/12/2024 14:08:11 - INFO - __main__ -     Best mrr:0.2347
10/12/2024 14:08:11 - INFO - __main__ -     ********************
10/12/2024 14:08:15 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 14:08:30 - INFO - __main__ -   epoch 0 step 800 loss 0.28036
10/12/2024 14:10:20 - INFO - __main__ -   epoch 0 step 900 loss 0.27889
10/12/2024 14:12:07 - INFO - __main__ -   epoch 0 step 1000 loss 0.27163
10/12/2024 14:13:56 - INFO - __main__ -   epoch 0 step 1100 loss 0.26005
10/12/2024 14:15:23 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:15:23 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:15:23 - INFO - __main__ -     Batch size = 64
10/12/2024 14:16:54 - INFO - __main__ -     eval_loss = 1.005
10/12/2024 14:16:54 - INFO - __main__ -     eval_mrr = 0.2802
10/12/2024 14:16:54 - INFO - __main__ -     ********************
10/12/2024 14:16:54 - INFO - __main__ -     Best mrr:0.2802
10/12/2024 14:16:54 - INFO - __main__ -     ********************
10/12/2024 14:16:57 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 14:17:20 - INFO - __main__ -   epoch 0 step 1200 loss 0.21447
10/12/2024 14:19:08 - INFO - __main__ -   epoch 0 step 1300 loss 0.21005
10/12/2024 14:20:57 - INFO - __main__ -   epoch 0 step 1400 loss 0.20882
10/12/2024 14:22:47 - INFO - __main__ -   epoch 0 step 1500 loss 0.2072
10/12/2024 14:24:05 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:24:05 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:24:05 - INFO - __main__ -     Batch size = 64
10/12/2024 14:25:35 - INFO - __main__ -     eval_loss = 0.8585
10/12/2024 14:25:35 - INFO - __main__ -     eval_mrr = 0.3144
10/12/2024 14:25:35 - INFO - __main__ -     ********************
10/12/2024 14:25:35 - INFO - __main__ -     Best mrr:0.3144
10/12/2024 14:25:35 - INFO - __main__ -     ********************
10/12/2024 14:25:39 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 14:26:10 - INFO - __main__ -   epoch 0 step 1600 loss 0.19527
10/12/2024 14:27:59 - INFO - __main__ -   epoch 0 step 1700 loss 0.19947
10/12/2024 14:29:49 - INFO - __main__ -   epoch 0 step 1800 loss 0.18814
10/12/2024 14:31:36 - INFO - __main__ -   epoch 0 step 1900 loss 0.18793
10/12/2024 14:32:47 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:32:47 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:32:47 - INFO - __main__ -     Batch size = 64
10/12/2024 14:34:16 - INFO - __main__ -     eval_loss = 0.8935
10/12/2024 14:34:16 - INFO - __main__ -     eval_mrr = 0.3017
10/12/2024 14:34:56 - INFO - __main__ -   epoch 0 step 2000 loss 0.18677
10/12/2024 14:36:43 - INFO - __main__ -   epoch 0 step 2100 loss 0.18185
10/12/2024 14:38:32 - INFO - __main__ -   epoch 0 step 2200 loss 0.18433
10/12/2024 14:40:22 - INFO - __main__ -   epoch 0 step 2300 loss 0.17966
10/12/2024 14:41:24 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:41:24 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:41:24 - INFO - __main__ -     Batch size = 64
10/12/2024 14:42:55 - INFO - __main__ -     eval_loss = 0.8649
10/12/2024 14:42:55 - INFO - __main__ -     eval_mrr = 0.3156
10/12/2024 14:42:55 - INFO - __main__ -     ********************
10/12/2024 14:42:55 - INFO - __main__ -     Best mrr:0.3156
10/12/2024 14:42:55 - INFO - __main__ -     ********************
10/12/2024 14:42:59 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 14:43:44 - INFO - __main__ -   epoch 0 step 2400 loss 0.16056
10/12/2024 14:45:34 - INFO - __main__ -   epoch 0 step 2500 loss 0.16381
10/12/2024 14:47:21 - INFO - __main__ -   epoch 0 step 2600 loss 0.17147
10/12/2024 14:49:11 - INFO - __main__ -   epoch 0 step 2700 loss 0.1704
10/12/2024 14:50:07 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:50:07 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:50:07 - INFO - __main__ -     Batch size = 64
10/12/2024 14:51:35 - INFO - __main__ -     eval_loss = 0.8809
10/12/2024 14:51:35 - INFO - __main__ -     eval_mrr = 0.3125
10/12/2024 14:52:28 - INFO - __main__ -   epoch 0 step 2800 loss 0.15956
10/12/2024 14:54:18 - INFO - __main__ -   epoch 0 step 2900 loss 0.17931
10/12/2024 14:56:07 - INFO - __main__ -   epoch 0 step 3000 loss 0.17563
10/12/2024 14:57:57 - INFO - __main__ -   epoch 0 step 3100 loss 0.16866
10/12/2024 14:58:44 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 14:58:44 - INFO - __main__ -     Num examples = 9604
10/12/2024 14:58:44 - INFO - __main__ -     Batch size = 64
10/12/2024 15:00:13 - INFO - __main__ -     eval_loss = 0.8764
10/12/2024 15:00:13 - INFO - __main__ -     eval_mrr = 0.3169
10/12/2024 15:00:13 - INFO - __main__ -     ********************
10/12/2024 15:00:13 - INFO - __main__ -     Best mrr:0.3169
10/12/2024 15:00:13 - INFO - __main__ -     ********************
10/12/2024 15:00:17 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 15:01:19 - INFO - __main__ -   epoch 0 step 3200 loss 0.15913
10/12/2024 15:03:07 - INFO - __main__ -   epoch 0 step 3300 loss 0.17497
10/12/2024 15:04:55 - INFO - __main__ -   epoch 0 step 3400 loss 0.17151
10/12/2024 15:06:45 - INFO - __main__ -   epoch 0 step 3500 loss 0.16605
10/12/2024 15:07:25 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:07:25 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:07:25 - INFO - __main__ -     Batch size = 64
10/12/2024 15:08:55 - INFO - __main__ -     eval_loss = 0.8271
10/12/2024 15:08:55 - INFO - __main__ -     eval_mrr = 0.3332
10/12/2024 15:08:55 - INFO - __main__ -     ********************
10/12/2024 15:08:55 - INFO - __main__ -     Best mrr:0.3332
10/12/2024 15:08:55 - INFO - __main__ -     ********************
10/12/2024 15:08:59 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 15:10:07 - INFO - __main__ -   epoch 0 step 3600 loss 0.15599
10/12/2024 15:11:57 - INFO - __main__ -   epoch 0 step 3700 loss 0.16026
10/12/2024 15:13:46 - INFO - __main__ -   epoch 0 step 3800 loss 0.16143
10/12/2024 15:15:34 - INFO - __main__ -   epoch 0 step 3900 loss 0.16094
10/12/2024 15:16:06 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:16:06 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:16:06 - INFO - __main__ -     Batch size = 64
10/12/2024 15:17:39 - INFO - __main__ -     eval_loss = 0.8354
10/12/2024 15:17:39 - INFO - __main__ -     eval_mrr = 0.3256
10/12/2024 15:19:33 - INFO - __main__ -   epoch 1 step 100 loss 0.15468
10/12/2024 15:21:23 - INFO - __main__ -   epoch 1 step 200 loss 0.15728
10/12/2024 15:23:12 - INFO - __main__ -   epoch 1 step 300 loss 0.15421
10/12/2024 15:24:47 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:24:47 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:24:47 - INFO - __main__ -     Batch size = 64
10/12/2024 15:26:18 - INFO - __main__ -     eval_loss = 0.8025
10/12/2024 15:26:18 - INFO - __main__ -     eval_mrr = 0.3352
10/12/2024 15:26:18 - INFO - __main__ -     ********************
10/12/2024 15:26:18 - INFO - __main__ -     Best mrr:0.3352
10/12/2024 15:26:18 - INFO - __main__ -     ********************
10/12/2024 15:26:22 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 15:26:35 - INFO - __main__ -   epoch 1 step 400 loss 0.19585
10/12/2024 15:28:24 - INFO - __main__ -   epoch 1 step 500 loss 0.163
10/12/2024 15:30:14 - INFO - __main__ -   epoch 1 step 600 loss 0.15552
10/12/2024 15:32:01 - INFO - __main__ -   epoch 1 step 700 loss 0.15381
10/12/2024 15:33:29 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:33:29 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:33:29 - INFO - __main__ -     Batch size = 64
10/12/2024 15:35:00 - INFO - __main__ -     eval_loss = 0.7907
10/12/2024 15:35:00 - INFO - __main__ -     eval_mrr = 0.3398
10/12/2024 15:35:00 - INFO - __main__ -     ********************
10/12/2024 15:35:00 - INFO - __main__ -     Best mrr:0.3398
10/12/2024 15:35:00 - INFO - __main__ -     ********************
10/12/2024 15:35:04 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 15:35:25 - INFO - __main__ -   epoch 1 step 800 loss 0.13802
10/12/2024 15:37:14 - INFO - __main__ -   epoch 1 step 900 loss 0.13808
10/12/2024 15:39:02 - INFO - __main__ -   epoch 1 step 1000 loss 0.12785
10/12/2024 15:40:52 - INFO - __main__ -   epoch 1 step 1100 loss 0.12954
10/12/2024 15:42:11 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:42:11 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:42:11 - INFO - __main__ -     Batch size = 64
10/12/2024 15:43:42 - INFO - __main__ -     eval_loss = 0.8157
10/12/2024 15:43:42 - INFO - __main__ -     eval_mrr = 0.3377
10/12/2024 15:44:10 - INFO - __main__ -   epoch 1 step 1200 loss 0.16771
10/12/2024 15:46:00 - INFO - __main__ -   epoch 1 step 1300 loss 0.15236
10/12/2024 15:47:49 - INFO - __main__ -   epoch 1 step 1400 loss 0.1523
10/12/2024 15:49:37 - INFO - __main__ -   epoch 1 step 1500 loss 0.15266
10/12/2024 15:50:51 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:50:51 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:50:51 - INFO - __main__ -     Batch size = 64
10/12/2024 15:52:22 - INFO - __main__ -     eval_loss = 0.7906
10/12/2024 15:52:22 - INFO - __main__ -     eval_mrr = 0.3409
10/12/2024 15:52:22 - INFO - __main__ -     ********************
10/12/2024 15:52:22 - INFO - __main__ -     Best mrr:0.3409
10/12/2024 15:52:22 - INFO - __main__ -     ********************
10/12/2024 15:52:26 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 15:53:01 - INFO - __main__ -   epoch 1 step 1600 loss 0.16862
10/12/2024 15:54:51 - INFO - __main__ -   epoch 1 step 1700 loss 0.14759
10/12/2024 15:56:39 - INFO - __main__ -   epoch 1 step 1800 loss 0.14194
10/12/2024 15:58:28 - INFO - __main__ -   epoch 1 step 1900 loss 0.13855
10/12/2024 15:59:33 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 15:59:33 - INFO - __main__ -     Num examples = 9604
10/12/2024 15:59:33 - INFO - __main__ -     Batch size = 64
10/12/2024 16:01:03 - INFO - __main__ -     eval_loss = 0.7696
10/12/2024 16:01:03 - INFO - __main__ -     eval_mrr = 0.345
10/12/2024 16:01:03 - INFO - __main__ -     ********************
10/12/2024 16:01:03 - INFO - __main__ -     Best mrr:0.345
10/12/2024 16:01:03 - INFO - __main__ -     ********************
10/12/2024 16:01:08 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 16:01:51 - INFO - __main__ -   epoch 1 step 2000 loss 0.11691
10/12/2024 16:03:40 - INFO - __main__ -   epoch 1 step 2100 loss 0.1327
10/12/2024 16:05:29 - INFO - __main__ -   epoch 1 step 2200 loss 0.1364
10/12/2024 16:07:17 - INFO - __main__ -   epoch 1 step 2300 loss 0.13699
10/12/2024 16:08:16 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 16:08:16 - INFO - __main__ -     Num examples = 9604
10/12/2024 16:08:16 - INFO - __main__ -     Batch size = 64
10/12/2024 16:09:46 - INFO - __main__ -     eval_loss = 0.7862
10/12/2024 16:09:46 - INFO - __main__ -     eval_mrr = 0.3428
10/12/2024 16:10:37 - INFO - __main__ -   epoch 1 step 2400 loss 0.13094
10/12/2024 16:12:26 - INFO - __main__ -   epoch 1 step 2500 loss 0.13854
10/12/2024 16:14:14 - INFO - __main__ -   epoch 1 step 2600 loss 0.14434
10/12/2024 16:16:03 - INFO - __main__ -   epoch 1 step 2700 loss 0.14219
10/12/2024 16:16:53 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 16:16:53 - INFO - __main__ -     Num examples = 9604
10/12/2024 16:16:53 - INFO - __main__ -     Batch size = 64
10/12/2024 16:18:24 - INFO - __main__ -     eval_loss = 0.783
10/12/2024 16:18:24 - INFO - __main__ -     eval_mrr = 0.3417
10/12/2024 16:19:24 - INFO - __main__ -   epoch 1 step 2800 loss 0.16703
10/12/2024 16:21:13 - INFO - __main__ -   epoch 1 step 2900 loss 0.14963
10/12/2024 16:23:01 - INFO - __main__ -   epoch 1 step 3000 loss 0.14751
10/12/2024 16:24:50 - INFO - __main__ -   epoch 1 step 3100 loss 0.14426
10/12/2024 16:25:32 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 16:25:32 - INFO - __main__ -     Num examples = 9604
10/12/2024 16:25:32 - INFO - __main__ -     Batch size = 64
10/12/2024 16:27:03 - INFO - __main__ -     eval_loss = 0.7745
10/12/2024 16:27:03 - INFO - __main__ -     eval_mrr = 0.3459
10/12/2024 16:27:03 - INFO - __main__ -     ********************
10/12/2024 16:27:03 - INFO - __main__ -     Best mrr:0.3459
10/12/2024 16:27:03 - INFO - __main__ -     ********************
10/12/2024 16:27:07 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 16:28:13 - INFO - __main__ -   epoch 1 step 3200 loss 0.13441
10/12/2024 16:30:03 - INFO - __main__ -   epoch 1 step 3300 loss 0.13518
10/12/2024 16:31:52 - INFO - __main__ -   epoch 1 step 3400 loss 0.14081
10/12/2024 16:33:40 - INFO - __main__ -   epoch 1 step 3500 loss 0.1415
10/12/2024 16:34:16 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 16:34:16 - INFO - __main__ -     Num examples = 9604
10/12/2024 16:34:16 - INFO - __main__ -     Batch size = 64
10/12/2024 16:35:47 - INFO - __main__ -     eval_loss = 0.7724
10/12/2024 16:35:47 - INFO - __main__ -     eval_mrr = 0.3464
10/12/2024 16:35:47 - INFO - __main__ -     ********************
10/12/2024 16:35:47 - INFO - __main__ -     Best mrr:0.3464
10/12/2024 16:35:47 - INFO - __main__ -     ********************
10/12/2024 16:35:51 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/12/2024 16:37:04 - INFO - __main__ -   epoch 1 step 3600 loss 0.13661
10/12/2024 16:38:54 - INFO - __main__ -   epoch 1 step 3700 loss 0.13483
10/12/2024 16:40:41 - INFO - __main__ -   epoch 1 step 3800 loss 0.13941
10/12/2024 16:42:31 - INFO - __main__ -   epoch 1 step 3900 loss 0.13991
10/12/2024 16:42:58 - INFO - __main__ -   ***** Running evaluation *****
10/12/2024 16:42:58 - INFO - __main__ -     Num examples = 9604
10/12/2024 16:42:58 - INFO - __main__ -     Batch size = 64
10/12/2024 16:44:28 - INFO - __main__ -     eval_loss = 0.7707
10/12/2024 16:44:28 - INFO - __main__ -     eval_mrr = 0.3465
10/12/2024 16:44:28 - INFO - __main__ -     ********************
10/12/2024 16:44:28 - INFO - __main__ -     Best mrr:0.3465
10/12/2024 16:44:28 - INFO - __main__ -     ********************
10/12/2024 16:44:33 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
