10/13/2024 12:41:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False, 16-bits training: False
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
10/13/2024 12:41:13 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/workspace/text-code/dataset/train.jsonl', output_dir='/workspace/text-code/saved_models', eval_data_file='/workspace/text-code/dataset/valid.jsonl', test_data_file='/workspace/text-code/dataset/test.jsonl', model_type='roberta', model_name_or_path='microsoft/graphcodebert-base', mlm=False, mlm_probability=0.15, config_name='microsoft/graphcodebert-base', tokenizer_name='microsoft/graphcodebert-base', cache_dir='', block_size=256, do_train=True, do_eval=False, do_test=False, evaluate_during_training=True, do_lower_case=False, train_batch_size=64, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=123456, epoch=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', n_gpu=2, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=32, start_epoch=0, start_step=0)
10/13/2024 12:43:26 - INFO - __main__ -   *** Example ***
10/13/2024 12:43:26 - INFO - __main__ -   idx: 0
10/13/2024 12:43:26 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
10/13/2024 12:43:26 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/13/2024 12:43:26 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
10/13/2024 12:43:26 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/13/2024 12:43:26 - INFO - __main__ -   *** Example ***
10/13/2024 12:43:26 - INFO - __main__ -   idx: 1
10/13/2024 12:43:26 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '."', '""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_"""', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '"""', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
10/13/2024 12:43:26 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/13/2024 12:43:26 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
10/13/2024 12:43:26 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/13/2024 12:43:26 - INFO - __main__ -   *** Example ***
10/13/2024 12:43:26 - INFO - __main__ -   idx: 2
10/13/2024 12:43:26 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
10/13/2024 12:43:26 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/13/2024 12:43:26 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
10/13/2024 12:43:26 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/opt/conda/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
10/13/2024 12:43:30 - INFO - __main__ -   ***** Running training *****
10/13/2024 12:43:30 - INFO - __main__ -     Num examples = 251820
10/13/2024 12:43:30 - INFO - __main__ -     Num Epochs = 2
10/13/2024 12:43:30 - INFO - __main__ -     Instantaneous batch size per GPU = 32
10/13/2024 12:43:30 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
10/13/2024 12:43:30 - INFO - __main__ -     Gradient Accumulation steps = 1
10/13/2024 12:43:30 - INFO - __main__ -     Total optimization steps = 7870
trainable params: 1,179,648 || all params: 125,825,280 || trainable%: 0.9375
/opt/conda/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
10/13/2024 12:45:20 - INFO - __main__ -   epoch 0 step 100 loss 15.42067
10/13/2024 12:47:10 - INFO - __main__ -   epoch 0 step 200 loss 11.91785
10/13/2024 12:48:59 - INFO - __main__ -   epoch 0 step 300 loss 8.43384
10/13/2024 12:50:46 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 12:50:46 - INFO - __main__ -     Num examples = 9604
10/13/2024 12:50:46 - INFO - __main__ -     Batch size = 64
10/13/2024 12:52:17 - INFO - __main__ -     eval_loss = 1.0505
10/13/2024 12:52:17 - INFO - __main__ -     eval_mrr = 0.347
10/13/2024 12:52:17 - INFO - __main__ -     ********************
10/13/2024 12:52:17 - INFO - __main__ -     Best mrr:0.347
10/13/2024 12:52:17 - INFO - __main__ -     ********************
10/13/2024 12:52:21 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 12:52:28 - INFO - __main__ -   epoch 0 step 400 loss 0.23694
10/13/2024 12:54:16 - INFO - __main__ -   epoch 0 step 500 loss 0.2624
10/13/2024 12:56:06 - INFO - __main__ -   epoch 0 step 600 loss 0.22937
10/13/2024 12:57:55 - INFO - __main__ -   epoch 0 step 700 loss 0.21421
10/13/2024 12:59:28 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 12:59:28 - INFO - __main__ -     Num examples = 9604
10/13/2024 12:59:28 - INFO - __main__ -     Batch size = 64
10/13/2024 13:00:59 - INFO - __main__ -     eval_loss = 0.8425
10/13/2024 13:00:59 - INFO - __main__ -     eval_mrr = 0.3581
10/13/2024 13:00:59 - INFO - __main__ -     ********************
10/13/2024 13:00:59 - INFO - __main__ -     Best mrr:0.3581
10/13/2024 13:00:59 - INFO - __main__ -     ********************
10/13/2024 13:01:03 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 13:01:20 - INFO - __main__ -   epoch 0 step 800 loss 0.17862
10/13/2024 13:03:08 - INFO - __main__ -   epoch 0 step 900 loss 0.15213
10/13/2024 13:04:57 - INFO - __main__ -   epoch 0 step 1000 loss 0.15431
10/13/2024 13:06:47 - INFO - __main__ -   epoch 0 step 1100 loss 0.14681
10/13/2024 13:08:12 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 13:08:12 - INFO - __main__ -     Num examples = 9604
10/13/2024 13:08:12 - INFO - __main__ -     Batch size = 64
10/13/2024 13:09:43 - INFO - __main__ -     eval_loss = 0.766
10/13/2024 13:09:43 - INFO - __main__ -     eval_mrr = 0.3773
10/13/2024 13:09:43 - INFO - __main__ -     ********************
10/13/2024 13:09:43 - INFO - __main__ -     Best mrr:0.3773
10/13/2024 13:09:43 - INFO - __main__ -     ********************
10/13/2024 13:09:47 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 13:10:10 - INFO - __main__ -   epoch 0 step 1200 loss 0.13011
10/13/2024 13:12:00 - INFO - __main__ -   epoch 0 step 1300 loss 0.12624
10/13/2024 13:13:49 - INFO - __main__ -   epoch 0 step 1400 loss 0.12459
10/13/2024 13:15:37 - INFO - __main__ -   epoch 0 step 1500 loss 0.12726
10/13/2024 13:16:57 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 13:16:57 - INFO - __main__ -     Num examples = 9604
10/13/2024 13:16:57 - INFO - __main__ -     Batch size = 64
10/13/2024 13:18:25 - INFO - __main__ -     eval_loss = 0.7358
10/13/2024 13:18:25 - INFO - __main__ -     eval_mrr = 0.3967
10/13/2024 13:18:25 - INFO - __main__ -     ********************
10/13/2024 13:18:25 - INFO - __main__ -     Best mrr:0.3967
10/13/2024 13:18:25 - INFO - __main__ -     ********************
10/13/2024 13:18:30 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 13:19:01 - INFO - __main__ -   epoch 0 step 1600 loss 0.11979
10/13/2024 13:20:49 - INFO - __main__ -   epoch 0 step 1700 loss 0.11921
10/13/2024 13:22:39 - INFO - __main__ -   epoch 0 step 1800 loss 0.11362
10/13/2024 13:24:28 - INFO - __main__ -   epoch 0 step 1900 loss 0.11976
10/13/2024 13:25:38 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 13:25:38 - INFO - __main__ -     Num examples = 9604
10/13/2024 13:25:38 - INFO - __main__ -     Batch size = 64
10/13/2024 13:27:09 - INFO - __main__ -     eval_loss = 0.6979
10/13/2024 13:27:09 - INFO - __main__ -     eval_mrr = 0.4061
10/13/2024 13:27:09 - INFO - __main__ -     ********************
10/13/2024 13:27:09 - INFO - __main__ -     Best mrr:0.4061
10/13/2024 13:27:09 - INFO - __main__ -     ********************
10/13/2024 13:27:13 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 13:27:51 - INFO - __main__ -   epoch 0 step 2000 loss 0.09175
10/13/2024 13:29:40 - INFO - __main__ -   epoch 0 step 2100 loss 0.11783
10/13/2024 13:31:28 - INFO - __main__ -   epoch 0 step 2200 loss 0.11899
10/13/2024 13:33:17 - INFO - __main__ -   epoch 0 step 2300 loss 0.11424
10/13/2024 13:34:20 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 13:34:20 - INFO - __main__ -     Num examples = 9604
10/13/2024 13:34:20 - INFO - __main__ -     Batch size = 64
10/13/2024 13:35:51 - INFO - __main__ -     eval_loss = 0.7105
10/13/2024 13:35:51 - INFO - __main__ -     eval_mrr = 0.4001
10/13/2024 13:36:38 - INFO - __main__ -   epoch 0 step 2400 loss 0.09706
10/13/2024 13:38:25 - INFO - __main__ -   epoch 0 step 2500 loss 0.1095
10/13/2024 13:40:14 - INFO - __main__ -   epoch 0 step 2600 loss 0.11021
10/13/2024 13:42:04 - INFO - __main__ -   epoch 0 step 2700 loss 0.1051
10/13/2024 13:42:59 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 13:42:59 - INFO - __main__ -     Num examples = 9604
10/13/2024 13:42:59 - INFO - __main__ -     Batch size = 64
10/13/2024 13:44:29 - INFO - __main__ -     eval_loss = 0.6845
10/13/2024 13:44:29 - INFO - __main__ -     eval_mrr = 0.4089
10/13/2024 13:44:29 - INFO - __main__ -     ********************
10/13/2024 13:44:29 - INFO - __main__ -     Best mrr:0.4089
10/13/2024 13:44:29 - INFO - __main__ -     ********************
10/13/2024 13:44:34 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 13:45:28 - INFO - __main__ -   epoch 0 step 2800 loss 0.09821
10/13/2024 13:47:15 - INFO - __main__ -   epoch 0 step 2900 loss 0.08965
10/13/2024 13:49:05 - INFO - __main__ -   epoch 0 step 3000 loss 0.09549
10/13/2024 13:50:55 - INFO - __main__ -   epoch 0 step 3100 loss 0.09592
10/13/2024 13:51:42 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 13:51:42 - INFO - __main__ -     Num examples = 9604
10/13/2024 13:51:42 - INFO - __main__ -     Batch size = 64
10/13/2024 13:53:13 - INFO - __main__ -     eval_loss = 0.691
10/13/2024 13:53:13 - INFO - __main__ -     eval_mrr = 0.4035
10/13/2024 13:54:13 - INFO - __main__ -   epoch 0 step 3200 loss 0.09034
10/13/2024 13:56:03 - INFO - __main__ -   epoch 0 step 3300 loss 0.09151
10/13/2024 13:57:52 - INFO - __main__ -   epoch 0 step 3400 loss 0.09455
10/13/2024 13:59:40 - INFO - __main__ -   epoch 0 step 3500 loss 0.09864
10/13/2024 14:00:20 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:00:20 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:00:20 - INFO - __main__ -     Batch size = 64
10/13/2024 14:01:51 - INFO - __main__ -     eval_loss = 0.6696
10/13/2024 14:01:51 - INFO - __main__ -     eval_mrr = 0.4083
10/13/2024 14:03:00 - INFO - __main__ -   epoch 0 step 3600 loss 0.0893
10/13/2024 14:04:49 - INFO - __main__ -   epoch 0 step 3700 loss 0.1012
10/13/2024 14:06:37 - INFO - __main__ -   epoch 0 step 3800 loss 0.09885
10/13/2024 14:08:27 - INFO - __main__ -   epoch 0 step 3900 loss 0.0971
10/13/2024 14:08:59 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:08:59 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:08:59 - INFO - __main__ -     Batch size = 64
10/13/2024 14:10:30 - INFO - __main__ -     eval_loss = 0.6442
10/13/2024 14:10:30 - INFO - __main__ -     eval_mrr = 0.4046
10/13/2024 14:12:25 - INFO - __main__ -   epoch 1 step 100 loss 0.08769
10/13/2024 14:14:15 - INFO - __main__ -   epoch 1 step 200 loss 0.08996
10/13/2024 14:16:03 - INFO - __main__ -   epoch 1 step 300 loss 0.0881
10/13/2024 14:17:39 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:17:39 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:17:39 - INFO - __main__ -     Batch size = 64
10/13/2024 14:19:10 - INFO - __main__ -     eval_loss = 0.6396
10/13/2024 14:19:10 - INFO - __main__ -     eval_mrr = 0.4169
10/13/2024 14:19:10 - INFO - __main__ -     ********************
10/13/2024 14:19:10 - INFO - __main__ -     Best mrr:0.4169
10/13/2024 14:19:10 - INFO - __main__ -     ********************
10/13/2024 14:19:15 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 14:19:28 - INFO - __main__ -   epoch 1 step 400 loss 0.14421
10/13/2024 14:21:17 - INFO - __main__ -   epoch 1 step 500 loss 0.09814
10/13/2024 14:23:05 - INFO - __main__ -   epoch 1 step 600 loss 0.09578
10/13/2024 14:24:55 - INFO - __main__ -   epoch 1 step 700 loss 0.09274
10/13/2024 14:26:24 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:26:24 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:26:24 - INFO - __main__ -     Batch size = 64
10/13/2024 14:27:52 - INFO - __main__ -     eval_loss = 0.6378
10/13/2024 14:27:52 - INFO - __main__ -     eval_mrr = 0.4145
10/13/2024 14:28:13 - INFO - __main__ -   epoch 1 step 800 loss 0.11382
10/13/2024 14:30:02 - INFO - __main__ -   epoch 1 step 900 loss 0.0953
10/13/2024 14:31:52 - INFO - __main__ -   epoch 1 step 1000 loss 0.09297
10/13/2024 14:33:40 - INFO - __main__ -   epoch 1 step 1100 loss 0.09176
10/13/2024 14:35:01 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:35:01 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:35:01 - INFO - __main__ -     Batch size = 64
10/13/2024 14:36:32 - INFO - __main__ -     eval_loss = 0.6518
10/13/2024 14:36:32 - INFO - __main__ -     eval_mrr = 0.4156
10/13/2024 14:37:00 - INFO - __main__ -   epoch 1 step 1200 loss 0.09537
10/13/2024 14:38:50 - INFO - __main__ -   epoch 1 step 1300 loss 0.09109
10/13/2024 14:40:37 - INFO - __main__ -   epoch 1 step 1400 loss 0.09353
10/13/2024 14:42:27 - INFO - __main__ -   epoch 1 step 1500 loss 0.08961
10/13/2024 14:43:41 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:43:41 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:43:41 - INFO - __main__ -     Batch size = 64
10/13/2024 14:45:09 - INFO - __main__ -     eval_loss = 0.6693
10/13/2024 14:45:09 - INFO - __main__ -     eval_mrr = 0.4121
10/13/2024 14:45:46 - INFO - __main__ -   epoch 1 step 1600 loss 0.0891
10/13/2024 14:47:34 - INFO - __main__ -   epoch 1 step 1700 loss 0.0836
10/13/2024 14:49:23 - INFO - __main__ -   epoch 1 step 1800 loss 0.08171
10/13/2024 14:51:13 - INFO - __main__ -   epoch 1 step 1900 loss 0.08479
10/13/2024 14:52:18 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 14:52:18 - INFO - __main__ -     Num examples = 9604
10/13/2024 14:52:18 - INFO - __main__ -     Batch size = 64
10/13/2024 14:53:48 - INFO - __main__ -     eval_loss = 0.6568
10/13/2024 14:53:48 - INFO - __main__ -     eval_mrr = 0.4188
10/13/2024 14:53:48 - INFO - __main__ -     ********************
10/13/2024 14:53:48 - INFO - __main__ -     Best mrr:0.4188
10/13/2024 14:53:48 - INFO - __main__ -     ********************
10/13/2024 14:53:52 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 14:54:35 - INFO - __main__ -   epoch 1 step 2000 loss 0.08497
10/13/2024 14:56:24 - INFO - __main__ -   epoch 1 step 2100 loss 0.07685
10/13/2024 14:58:14 - INFO - __main__ -   epoch 1 step 2200 loss 0.08209
10/13/2024 15:00:01 - INFO - __main__ -   epoch 1 step 2300 loss 0.08391
10/13/2024 15:01:01 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 15:01:01 - INFO - __main__ -     Num examples = 9604
10/13/2024 15:01:01 - INFO - __main__ -     Batch size = 64
10/13/2024 15:02:31 - INFO - __main__ -     eval_loss = 0.6223
10/13/2024 15:02:31 - INFO - __main__ -     eval_mrr = 0.4255
10/13/2024 15:02:31 - INFO - __main__ -     ********************
10/13/2024 15:02:31 - INFO - __main__ -     Best mrr:0.4255
10/13/2024 15:02:31 - INFO - __main__ -     ********************
10/13/2024 15:02:35 - INFO - __main__ -   Saving model checkpoint to /workspace/text-code/saved_models/checkpoint-best-mrr/model.bin
10/13/2024 15:03:26 - INFO - __main__ -   epoch 1 step 2400 loss 0.10003
10/13/2024 15:05:16 - INFO - __main__ -   epoch 1 step 2500 loss 0.08556
10/13/2024 15:07:03 - INFO - __main__ -   epoch 1 step 2600 loss 0.08544
10/13/2024 15:08:53 - INFO - __main__ -   epoch 1 step 2700 loss 0.08518
10/13/2024 15:09:42 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 15:09:42 - INFO - __main__ -     Num examples = 9604
10/13/2024 15:09:42 - INFO - __main__ -     Batch size = 64
10/13/2024 15:11:13 - INFO - __main__ -     eval_loss = 0.6437
10/13/2024 15:11:13 - INFO - __main__ -     eval_mrr = 0.4211
10/13/2024 15:12:11 - INFO - __main__ -   epoch 1 step 2800 loss 0.06925
10/13/2024 15:14:01 - INFO - __main__ -   epoch 1 step 2900 loss 0.07782
10/13/2024 15:15:50 - INFO - __main__ -   epoch 1 step 3000 loss 0.08059
10/13/2024 15:17:38 - INFO - __main__ -   epoch 1 step 3100 loss 0.0827
10/13/2024 15:18:22 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 15:18:22 - INFO - __main__ -     Num examples = 9604
10/13/2024 15:18:22 - INFO - __main__ -     Batch size = 64
10/13/2024 15:19:51 - INFO - __main__ -     eval_loss = 0.6392
10/13/2024 15:19:51 - INFO - __main__ -     eval_mrr = 0.424
10/13/2024 15:20:59 - INFO - __main__ -   epoch 1 step 3200 loss 0.0787
10/13/2024 15:22:47 - INFO - __main__ -   epoch 1 step 3300 loss 0.08713
10/13/2024 15:24:35 - INFO - __main__ -   epoch 1 step 3400 loss 0.08583
10/13/2024 15:26:25 - INFO - __main__ -   epoch 1 step 3500 loss 0.08732
10/13/2024 15:26:59 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 15:26:59 - INFO - __main__ -     Num examples = 9604
10/13/2024 15:26:59 - INFO - __main__ -     Batch size = 64
10/13/2024 15:28:30 - INFO - __main__ -     eval_loss = 0.6396
10/13/2024 15:28:30 - INFO - __main__ -     eval_mrr = 0.4239
10/13/2024 15:29:44 - INFO - __main__ -   epoch 1 step 3600 loss 0.08799
10/13/2024 15:31:32 - INFO - __main__ -   epoch 1 step 3700 loss 0.08947
10/13/2024 15:33:21 - INFO - __main__ -   epoch 1 step 3800 loss 0.08211
10/13/2024 15:35:11 - INFO - __main__ -   epoch 1 step 3900 loss 0.08633
10/13/2024 15:35:38 - INFO - __main__ -   ***** Running evaluation *****
10/13/2024 15:35:38 - INFO - __main__ -     Num examples = 9604
10/13/2024 15:35:38 - INFO - __main__ -     Batch size = 64
10/13/2024 15:37:08 - INFO - __main__ -     eval_loss = 0.6386
10/13/2024 15:37:08 - INFO - __main__ -     eval_mrr = 0.4232
